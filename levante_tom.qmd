---
title: "Untitled"
format: html
editor: visual
---

```{r}
library(tidyverse)
library(janitor)
library(mirt)
library(here)
library(ggrepel)
library(knitr)
library(brms)
library(tidybayes)
library(ggthemes)
library(coda)
library(lavaan)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}

func <- function(x){
  abs(1-x)
}
```

```{r}
d1 <- readxl::read_xlsx(here("data","ToMBooklet1-Data.xlsx"), 
                        sheet = 1) |> clean_names()
i1 <- readxl::read_xlsx(here("data","ToMBooklet1-Data.xlsx"), 
                        sheet = 2) |> clean_names()
s1 <- readxl::read_xlsx(here("data","ToMBooklet1-Data.xlsx"), 
                        sheet = 4) |> clean_names()
d2 <- readxl::read_xlsx(here("data","ToMBooklet2-Data.xlsx"), 
                        sheet = 1) |> clean_names()
i2 <- readxl::read_xlsx(here("data","ToMBooklet2-Data.xlsx"), 
                        sheet = 2) |> clean_names()
s2 <- readxl::read_xlsx(here("data","ToMBooklet2-Data.xlsx"), 
                        sheet = 4) |> clean_names()
```

Merge.

```{r}
d1 <- d1 |>
  left_join(select(s1, sub_id, age)) |>
  left_join(i1)

d2 <- d2 |>
  left_join(select(s2, sub_id, age)) |>
  left_join(i2)

d <- bind_rows(d1 |> mutate(dataset = "1"),
               d2 |> mutate(dataset = "2")) |>
  mutate(answer = as.numeric(answer_0_1)) 
```

Plot.

```{r}
ms <- d |>
  group_by(sub_id, dataset, age) |>
  summarise(prop_correct = mean(answer, na.rm=TRUE)) 

ggplot(ms, aes(x = age, y = prop_correct, col = dataset)) + 
  geom_point() +
  geom_smooth() 
```

Items. There are some items with NA `q_id` fields. Maybe because of translation? The question text seems different...

```{r}
is <- d |>
  filter(!is.na(q_id)) |>
  group_by(q_id, question, dataset) |>
  summarise(prop_correct = mean(answer, na.rm=TRUE)) 

ggplot(is, aes(x = prop_correct, fill = dataset)) + 
  geom_histogram()

kable(is |>
        arrange(dataset, desc(prop_correct)))
```

Reshape to IRT matrix? No question overlap.

```{r}
d1_wide <- filter(d, dataset == 1, 
                 !is.na(q_id)) |>
  select(sub_id, q_id, answer) |>
  pivot_wider(names_from = "q_id", values_from = "answer") 

d1_mat <- d1_wide |>
  select(-sub_id) |>
  data.frame() |>
  data.matrix()

colnames(d1_mat) <- names(d1_wide)[-1]
rownames(d1_mat) <- d1_wide$sub_id

# Requires no empty rows - `personfit` doesn't work with `removeEmptyRows=TRUE` even though the model fit will work that way. 
# d_mat_ws <- d_mat_ws[complete.cases(d_mat_ws),]
```

Fit IRT.

```{r}
mod_2pl <- mirt(d1_mat, 1, itemtype='2PL', verbose=TRUE, 
                technical = list(NCYCLES = 2000))

coefs_2pl <- as_tibble(coef(mod_2pl, simplify = TRUE)$items) %>%
  mutate(q_id = rownames(coef(mod_2pl, simplify = TRUE)$items))
fscores_2pl <- tibble(sub_id = rownames(d1_mat), 
                         ability = fscores(mod_2pl, method = "MAP")[,1])

```

Plot.

```{r}
coefs_2pl <- left_join(coefs_2pl, i1)

ggplot(coefs_2pl, aes(x = -a1, y = d)) + 
  geom_point() + 
  geom_label_repel(aes(label = question))
```

One Q is too easy, remove. Other than that, the distribution looks good.

```{r}
ggplot(filter(coefs_2pl, a1 < 10),
       aes(x = -a1, y = d, col = concept_super)) + 
  geom_point() 
```

# Rasch Models

```{r}
d1_rasch <- d1|>
  filter(qtype == "2AFC", 
         answer_0_1 != "NA")|>
  mutate(correct = as.numeric(answer_0_1))

d2_rasch <- d2|>
  filter(qtype == "2AFC", 
         answer_0_1 != "NA")|>
  mutate(correct = as.numeric(answer_0_1))
```

# Dataset 1

## Rasch Model

Fit Rasch model with guessing probability built in.

```{r}
# prior_rasch <- prior("normal(0, 2)", class = "b", nlpar = "eta") +
#   prior("normal(0, 1)", class = "sd", group = "sub_id", nlpar = "eta") +
#   prior("normal(0, 3)", class = "sd", group = "question_id", nlpar = "eta")
# 
# rasch_m <- brm(
#   data = d1_rasch,
#   family = brmsfamily("bernoulli", "identity"),
#   bf(
#     correct ~ 0.5 + 0.5 * inv_logit(eta),
#     eta ~ 1 + (1 | question_id) + (1 | sub_id),
#     nl = TRUE
#   ),
#   prior = prior_rasch,
#   control = list(adapt_delta = 0.95, max_treedepth = 12),
#   cores = 3,
#   chains = 3,
#   iter = 4000
# )
# 
# saveRDS(rasch_m, "./saves/rasch_m.rds")

rasch_m <- readRDS("./saves/rasch_m.rds")


```

### ICC

```{r}
icc_rasch <- posterior_samples(rasch_m)%>% 
  select(b_eta_Intercept, starts_with("r_question_id"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_question_id"), names_to = "item", values_to = "xi") %>%
  mutate(item = str_extract(string = item, pattern = "(?<=\\[).*(?=,Intercept\\])"))%>%
  expand(nesting(iter, b_eta_Intercept, item, xi),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = 0.5 + 0.5*inv_logit_scaled((b_eta_Intercept + theta + xi))) %>%  
  group_by(theta, item) %>% 
  summarise(p = mean(p))%>%
  left_join(d1_rasch%>%select(question_id,concept_super)%>%rename(item = question_id)%>%distinct(item, .keep_all = T))
```

```{r}
icc_rasch %>% 
  #filter(item %in% sel_items_rasch)%>%
  ggplot(aes(x = theta, y = p,group = item, col = concept_super)) +
  geom_line() +
  #facet_wrap(~group)+
  #guides(col = F)+
  geom_hline(yintercept = 0.5, lty = 3, alpha = .75)+
  scale_color_viridis_d(name = "AoA") +
  labs(title = "ICCs for the 1PL",
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  ylim(0,1)+
  theme_minimal()
```

## Fit indices

Compute in and outfit to see how well individual items fit the Rasch model.

```{r}
fit_indices <- d1_rasch%>%
  add_epred_draws(rasch_m, re_formula = ~(1 | question_id) + (1 | sub_id), ndraws = 5000)%>%
  mutate(zvi = (correct - .epred)/(.epred*(1-.epred))^0.5)%>%
  group_by(question_id,.draw)%>%
  summarise(outfit = sum(zvi^2)/length(unique(sub_id)),
            infit = (sum(zvi^2*(.epred*(1-.epred)))/sum(.epred*(1-.epred))))
```

```{r}
fit_indices%>%
  pivot_longer(names_to = "fit_index", values_to = "value", cols = c(outfit, infit))%>%
  ggplot(. , aes(y = question_id, x = value, col = fit_index))+
  geom_vline(xintercept = c(0.7, 1.3), lty = 3, alpha = .5)+
  geom_vline(xintercept = c(0.5, 1.5), lty = 2, alpha = .5)+
  geom_vline(xintercept = 1, lty = 1, alpha = .5, col = "darkgreen")+
  stat_halfeye(alpha = .75, .width = c(0.66, 0.95), position = position_dodge(width = .5))+
  scale_fill_colorblind()+
  scale_color_colorblind(name = "Fit index")+
    labs(x = "Index value", y = "Item")+
  #facet_grid(~fit_index)+
  scale_x_continuous(breaks = c(0,0.5, 07, 1, 1.3, 1.5), labels = c(0,0.5, 07, 1, 1.3, 1.5), limits = c(0,7))+
  theme_bw()+
  theme(legend.position = c(0.8,0.8))
```

```{r}
ggsave("./graphs/fit_indices.png", height = 8, width = 6, scale = 1.2)
```

Use (somewhat arbitrary) cut-offs from the literature to select well-fitting items.

```{r}
rasch_fit_mode <- fit_indices%>%
  pivot_longer(names_to = "fit_index", values_to = "value", cols = c(outfit, infit))%>%
  group_by(question_id, fit_index)%>%
  summarise(mode = estimate_mode(value),
            lci = hdi_lower(value),
            uci = hdi_upper(value))


rasch_sel_items <- rasch_fit_mode%>%
  select(-lci, -uci)%>%
  pivot_wider(names_from = fit_index, values_from = mode)%>%
  filter(0.7 < infit & 1.3 > infit,
         0.7 < outfit & 1.3 > outfit)%>%
  pull(question_id)
```

Which questions are selected?

```{r}
d1_rasch|>
  filter(question_id %in% rasch_sel_items)|>
  distinct(question_id, .keep_all = T)|>
  select(question_id, concept_super, question)
```

## Rasch with selected items

Re-fit rasch model with selected items.

```{r}
# rasch_m_sel <- brm(
#   data = d1_rasch|>filter(question_id %in% rasch_sel_items),
#   family = brmsfamily("bernoulli", "identity"),
#   bf(
#     correct ~ 0.5 + 0.5 * inv_logit(eta),
#     eta ~ 1 + (1 | question_id) + (1 | sub_id),
#     nl = TRUE
#   ),
#   prior = prior_rasch,
#   control = list(adapt_delta = 0.95, max_treedepth = 12),
#   cores = 3,
#   chains = 3,
#   iter = 4000
# )%>%add_criterion(c("loo"))
# 
# saveRDS(rasch_m_sel, "./saves/rasch_m_sel.rds")

rasch_m_sel <- readRDS("./saves/rasch_m_sel.rds")
```

### ICC

```{r}
icc_rasch_sel <- posterior_samples(rasch_m_sel)%>% 
  select(b_eta_Intercept, starts_with("r_question_id"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_question_id"), names_to = "item", values_to = "xi") %>%
  mutate(item = str_extract(string = item, pattern = "(?<=\\[).*(?=,Intercept\\])"))%>%
  expand(nesting(iter, b_eta_Intercept, item, xi),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = 0.5 + 0.5*inv_logit_scaled((b_eta_Intercept + theta + xi))) %>%  
  group_by(theta, item) %>% 
  summarise(p = mean(p))%>%
  left_join(d1_rasch%>%select(question_id,concept_super)%>%rename(item = question_id)%>%distinct(item, .keep_all = T))
```

```{r}
icc_rasch_sel %>% 
  #filter(item %in% sel_items_rasch)%>%
  ggplot(aes(x = theta, y = p,group = item, col = concept_super)) +
  geom_line() +
  #facet_wrap(~group)+
  #guides(col = F)+
  geom_hline(yintercept = 0.5, lty = 3, alpha = .75)+
  scale_color_viridis_d(name = "Category") +
  labs(title = "ICCs for the 1PL",
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  ylim(0,1)+
  theme_minimal()
```

### Frequentist fit indices

Compute model fit indices. They are not terrible, but not above/below conventional thresholds.

```{r}
frq_fit_dat <- d1_rasch%>%
  filter(question_id %in% rasch_sel_items)%>%
  select(sub_id, question_id, correct)%>%
  pivot_wider(names_from = question_id, values_from = correct)%>%
  select( -sub_id)%>%
  na.omit()

# using lavaan, no idea how to build in the guessing rate

modelx <- paste(paste0("1*",rasch_sel_items, "+"), collapse = " ")

model <- paste0("f =~", substr(modelx, 1, nchar(modelx)-1))

freq <- sem(model, frq_fit_dat, ordered =TRUE, parameterization = "theta")
 
fitMeasures(freq)%>%as_tibble(rownames = "index")%>%
  filter(index == "rmsea" | index == "cfi" | index == "srmr")

# using mirt

freq_mirt <- mirt(frq_fit_dat, 1, itemtype='Rasch', verbose=TRUE, guess = 0.5,na.rm=TRUE,
                technical = list(NCYCLES = 2000))

M2(freq_mirt)
```

## 2PL

Fit 2PL model for comparison.

```{r}

# prior_2PL <- 
#   prior("normal(0, 2)", class = "b", nlpar = "eta") +
#   prior("normal(0, 1)", class = "b", nlpar = "logalpha") +
#   prior("normal(0, 1)", class = "sd", group = "sub_id", nlpar = "eta") + 
#   prior("normal(0, 3)", class = "sd", group = "question_id", nlpar = "eta") +
#   prior("normal(0, 1)", class = "sd", group = "question_id", nlpar = "logalpha")
# 
# m_2PL_sel <- brm(
#   data = d1_rasch|>filter(question_id %in% rasch_sel_items),
#   family = brmsfamily("bernoulli", "identity"),
#   bf(
#     correct ~ 0.5 + 0.5 * inv_logit(exp(logalpha) * eta),
#     eta ~ 1 + (1 |i| question_id) + (1 | sub_id),
#     logalpha ~ 1 + (1 |i| question_id),
#     nl = TRUE
#   ),
#   prior = prior_2PL,
#   control = list(adapt_delta = 0.95, max_treedepth = 12),
#   cores = 3,
#   chains = 3,
#   iter = 4000
# )%>%add_criterion(c("loo"))
# 
# saveRDS(m_2PL_sel, "./saves/m_2PL_sel.rds")

m_2PL_sel <- readRDS("./saves/m_2PL_sel.rds")
```

### ICC

```{r}
icc_2PL_sel <- posterior_samples(m_2PL_sel)%>% 
  select(b_eta_Intercept, b_logalpha_Intercept, starts_with("r_question_id"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_question_id")) %>%
  mutate(item      = str_extract(name, pattern = "(?<=\\[).*(?=,Intercept\\])"),
         parameter = ifelse(str_detect(name, "eta"), "xi", "logalpha"))%>%
  select(-name) %>% 
  pivot_wider(names_from = parameter, values_from = value)%>% 
  expand(nesting(iter, b_eta_Intercept, b_logalpha_Intercept, item, xi, logalpha),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  # note the difference in the equation
  mutate(p = 0.5 + 0.5*inv_logit_scaled(exp(b_logalpha_Intercept + logalpha) * (b_eta_Intercept + theta + xi))) %>% 
  group_by(theta, item) %>% 
  summarise(p = mean(p))%>%
  left_join(d1_rasch%>%select(question_id,concept_super)%>%rename(item = question_id)%>%distinct(item, .keep_all = T))


```

```{r}
icc_2PL_sel %>% 
  #filter(item %in% sel_items_rasch)%>%
  ggplot(aes(x = theta, y = p,group = item, col = concept_super)) +
  geom_line() +
  #facet_wrap(~group)+
  #guides(col = F)+
  geom_hline(yintercept = 0.5, lty = 3, alpha = .75)+
  scale_color_viridis_d(name = "Category") +
  labs(title = "ICCs for the 2PL",
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  ylim(0,1)+
  theme_minimal()
```

Items from the Reference category seem to be a bit problematic.

## Compare models with selected items

2PL fits substantially better.

```{r}
loo_compare(rasch_m_sel, m_2PL_sel, criterion = "loo")%>%as_tibble(rownames = "model")
```

# Dataset 2

## Rasch Model

Fit Rasch model with guessing probability built in.

```{r}
prior_rasch <- prior("normal(0, 2)", class = "b", nlpar = "eta") +
  prior("normal(0, 1)", class = "sd", group = "sub_id", nlpar = "eta") +
  prior("normal(0, 3)", class = "sd", group = "question_id", nlpar = "eta")

rasch_m2 <- brm(
  data = d2_rasch,
  family = brmsfamily("bernoulli", "identity"),
  bf(
    correct ~ 0.5 + 0.5 * inv_logit(eta),
    eta ~ 1 + (1 | question_id) + (1 | sub_id),
    nl = TRUE
  ),
  prior = prior_rasch,
  control = list(adapt_delta = 0.95, max_treedepth = 12),
  cores = 3,
  chains = 3,
  iter = 4000
)

saveRDS(rasch_m2, "./saves/rasch_m2.rds")

rasch_m2 <- readRDS("./saves/rasch_m2.rds")
```

### ICC

```{r}
icc_rasch2 <- posterior_samples(rasch_m2)%>% 
  select(b_eta_Intercept, starts_with("r_question_id"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_question_id"), names_to = "item", values_to = "xi") %>%
  mutate(item = str_extract(string = item, pattern = "(?<=\\[).*(?=,Intercept\\])"))%>%
  expand(nesting(iter, b_eta_Intercept, item, xi),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = 0.5 + 0.5*inv_logit_scaled((b_eta_Intercept + theta + xi))) %>%  
  group_by(theta, item) %>% 
  summarise(p = mean(p))%>%
  left_join(d2_rasch%>%select(question_id,concept_super)%>%rename(item = question_id)%>%distinct(item, .keep_all = T))
```

```{r}
icc_rasch2 %>% 
  #filter(item %in% sel_items_rasch)%>%
  ggplot(aes(x = theta, y = p,group = item, col = concept_super)) +
  geom_line() +
  #facet_wrap(~group)+
  #guides(col = F)+
  geom_hline(yintercept = 0.5, lty = 3, alpha = .75)+
  scale_color_viridis_d(name = "AoA") +
  labs(title = "ICCs for the 1PL",
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  ylim(0,1)+
  theme_minimal()
```

### Fit indices

Compute in and outfit to see how well individual items fit the Rasch model.

```{r}
fit_indices2 <- d2_rasch%>%
  add_epred_draws(rasch_m2, re_formula = ~(1 | question_id) + (1 | sub_id), ndraws = 5000)%>%
  mutate(zvi = (correct - .epred)/(.epred*(1-.epred))^0.5)%>%
  group_by(question_id,.draw)%>%
  summarise(outfit = sum(zvi^2)/length(unique(sub_id)),
            infit = (sum(zvi^2*(.epred*(1-.epred)))/sum(.epred*(1-.epred))))
```

```{r}
fit_indices2%>%
  pivot_longer(names_to = "fit_index", values_to = "value", cols = c(outfit, infit))%>%
  ggplot(. , aes(y = question_id, x = value, col = fit_index))+
  geom_vline(xintercept = c(0.7, 1.3), lty = 3, alpha = .5)+
  geom_vline(xintercept = c(0.5, 1.5), lty = 2, alpha = .5)+
  geom_vline(xintercept = 1, lty = 1, alpha = .5, col = "darkgreen")+
  stat_halfeye(alpha = .75, .width = c(0.66, 0.95), position = position_dodge(width = .5))+
  scale_fill_colorblind()+
  scale_color_colorblind(name = "Fit index")+
    labs(x = "Index value", y = "Item")+
  #facet_grid(~fit_index)+
  scale_x_continuous(breaks = c(0,0.5, 07, 1, 1.3, 1.5), labels = c(0,0.5, 07, 1, 1.3, 1.5), limits = c(0,7))+
  theme_bw()+
  theme(legend.position = c(0.8,0.8))
```

```{r}
ggsave("./graphs/fit_indices2.png", height = 8, width = 6, scale = 1.2)
```

Use (somewhat arbitrary) cut-offs from the literature to select well-fitting items.

```{r}
rasch_fit_mode2 <- fit_indices2%>%
  pivot_longer(names_to = "fit_index", values_to = "value", cols = c(outfit, infit))%>%
  group_by(question_id, fit_index)%>%
  summarise(mode = estimate_mode(value),
            lci = hdi_lower(value),
            uci = hdi_upper(value))


rasch_sel_items2 <- rasch_fit_mode2%>%
  select(-lci, -uci)%>%
  pivot_wider(names_from = fit_index, values_from = mode)%>%
  filter(0.7 < infit & 1.3 > infit,
         0.7 < outfit & 1.3 > outfit)%>%
  pull(question_id)
```

Which questions are selected?

```{r}
d2_rasch|>
  filter(question_id %in% rasch_sel_items2)|>
  distinct(question_id, .keep_all = T)|>
  select(question_id, concept_super, question)
```

## Rasch with selected items

Re-fit rasch model with selected items.

```{r}
rasch_m_sel2 <- brm(
  data = d2_rasch|>filter(question_id %in% rasch_sel_items2),
  family = brmsfamily("bernoulli", "identity"),
  bf(
    correct ~ 0.5 + 0.5 * inv_logit(eta),
    eta ~ 1 + (1 | question_id) + (1 | sub_id),
    nl = TRUE
  ),
  prior = prior_rasch,
  control = list(adapt_delta = 0.95, max_treedepth = 12),
  cores = 3,
  chains = 3,
  iter = 4000
)%>%add_criterion(c("loo"))

saveRDS(rasch_m_sel2, "./saves/rasch_m_sel2.rds")

rasch_m_sel2 <- readRDS("./saves/rasch_m_sel2.rds")
```

### ICC

```{r}
icc_rasch_sel2 <- posterior_samples(rasch_m_sel2)%>% 
  select(b_eta_Intercept, starts_with("r_question_id"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_question_id"), names_to = "item", values_to = "xi") %>%
  mutate(item = str_extract(string = item, pattern = "(?<=\\[).*(?=,Intercept\\])"))%>%
  expand(nesting(iter, b_eta_Intercept, item, xi),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = 0.5 + 0.5*inv_logit_scaled((b_eta_Intercept + theta + xi))) %>%  
  group_by(theta, item) %>% 
  summarise(p = mean(p))%>%
  left_join(d2_rasch%>%select(question_id,concept_super)%>%rename(item = question_id)%>%distinct(item, .keep_all = T))
```

```{r}
icc_rasch_sel2 %>% 
  #filter(item %in% sel_items_rasch)%>%
  ggplot(aes(x = theta, y = p,group = item, col = concept_super)) +
  geom_line() +
  #facet_wrap(~group)+
  #guides(col = F)+
  geom_hline(yintercept = 0.5, lty = 3, alpha = .75)+
  scale_color_viridis_d(name = "Category") +
  labs(title = "ICCs for the 1PL",
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  ylim(0,1)+
  theme_minimal()
```

### Frequentist fit indices

Compute model fit indices. This time, they are pretty bad, especially the CFI

```{r}
frq_fit_dat2 <- d2_rasch%>%
  filter(question_id %in% rasch_sel_items2)%>%
  select(sub_id, question_id, correct)%>%
  distinct(sub_id, question_id, .keep_all = T)%>%
  pivot_wider(names_from = question_id, values_from = correct)%>%
  select( -sub_id)%>%
  na.omit()

# using lavaan, no idea how to build in the guessing rate

modelx2 <- paste(paste0("1*",rasch_sel_items2, "+"), collapse = " ")

model2 <- paste0("f =~", substr(modelx2, 1, nchar(modelx2)-1))

freq2 <- sem(model2, frq_fit_dat2, ordered =TRUE, parameterization = "theta")
 
fitMeasures(freq2)%>%as_tibble(rownames = "index")%>%
  filter(index == "rmsea" | index == "cfi" | index == "srmr")

# using mirt

freq_mirt2 <- mirt(frq_fit_dat2, 1, itemtype='Rasch', verbose=TRUE, guess = 0.5,na.rm=TRUE,
                technical = list(NCYCLES = 2000))

M2(freq_mirt2)
```

## 2PL

Fit 2PL model for comparison.

```{r}

prior_2PL <-
  prior("normal(0, 2)", class = "b", nlpar = "eta") +
  prior("normal(0, 1)", class = "b", nlpar = "logalpha") +
  prior("normal(0, 1)", class = "sd", group = "sub_id", nlpar = "eta") +
  prior("normal(0, 3)", class = "sd", group = "question_id", nlpar = "eta") +
  prior("normal(0, 1)", class = "sd", group = "question_id", nlpar = "logalpha")

m_2PL_sel2 <- brm(
  data = d2_rasch|>filter(question_id %in% rasch_sel_items2),
  family = brmsfamily("bernoulli", "identity"),
  bf(
    correct ~ 0.5 + 0.5 * inv_logit(exp(logalpha) * eta),
    eta ~ 1 + (1 |i| question_id) + (1 | sub_id),
    logalpha ~ 1 + (1 |i| question_id),
    nl = TRUE
  ),
  prior = prior_2PL,
  control = list(adapt_delta = 0.95, max_treedepth = 12),
  cores = 3,
  chains = 3,
  iter = 4000
)%>%add_criterion(c("loo"))

saveRDS(m_2PL_sel2, "./saves/m_2PL_sel2.rds")

m_2PL_sel2 <- readRDS("./saves/m_2PL_sel2.rds")
```

### ICC

```{r}
icc_2PL_sel2 <- posterior_samples(m_2PL_sel2)%>% 
  select(b_eta_Intercept, b_logalpha_Intercept, starts_with("r_question_id"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_question_id")) %>%
  mutate(item      = str_extract(name, pattern = "(?<=\\[).*(?=,Intercept\\])"),
         parameter = ifelse(str_detect(name, "eta"), "xi", "logalpha"))%>%
  select(-name) %>% 
  pivot_wider(names_from = parameter, values_from = value)%>% 
  expand(nesting(iter, b_eta_Intercept, b_logalpha_Intercept, item, xi, logalpha),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  # note the difference in the equation
  mutate(p = 0.5 + 0.5*inv_logit_scaled(exp(b_logalpha_Intercept + logalpha) * (b_eta_Intercept + theta + xi))) %>% 
  group_by(theta, item) %>% 
  summarise(p = mean(p))%>%
  left_join(d2_rasch%>%select(question_id,concept_super)%>%rename(item = question_id)%>%distinct(item, .keep_all = T))


```

```{r}
icc_2PL_sel2 %>% 
  #filter(item %in% sel_items_rasch)%>%
  ggplot(aes(x = theta, y = p,group = item, col = concept_super)) +
  geom_line() +
  #facet_wrap(~group)+
  #guides(col = F)+
  geom_hline(yintercept = 0.5, lty = 3, alpha = .75)+
  scale_color_viridis_d(name = "Category") +
  labs(title = "ICCs for the 2PL",
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  ylim(0,1)+
  theme_minimal()
```

Items from the Reference category seem to be a bit problematic.

## Compare models with selected items

2PL fits substantially better.

```{r}
loo_compare(rasch_m_sel2, m_2PL_sel2, criterion = "loo")%>%as_tibble(rownames = "model")
```

# Automated item selection

## 2PL models with all items

To get discrimination parameters

```{r}
# prior_2PL <-
#   prior("normal(0, 2)", class = "b", nlpar = "eta") +
#   prior("normal(0, 1)", class = "b", nlpar = "logalpha") +
#   prior("normal(0, 1)", class = "sd", group = "sub_id", nlpar = "eta") +
#   prior("normal(0, 3)", class = "sd", group = "question_id", nlpar = "eta") +
#   prior("normal(0, 1)", class = "sd", group = "question_id", nlpar = "logalpha")
# 
# m_2PL <- brm(
#   data = d1_rasch,
#   family = brmsfamily("bernoulli", "identity"),
#   bf(
#     correct ~ 0.5 + 0.5 * inv_logit(exp(logalpha) * eta),
#     eta ~ 1 + (1 |i| question_id) + (1 | sub_id),
#     logalpha ~ 1 + (1 |i| question_id),
#     nl = TRUE
#   ),
#   prior = prior_2PL,
#   control = list(adapt_delta = 0.95, max_treedepth = 12),
#   cores = 3,
#   chains = 3,
#   iter = 4000,
#   threads = threading(8), #to speed things up, comment out if not on a cluster
#   backend = "cmdstanr" #to speed things up, comment out if not on a cluster
# )%>%add_criterion(c("loo"))
# 
# saveRDS(m_2PL, "./saves/m_2PL.rds")

m_2PL <- readRDS("./saves/m_2PL.rds")


# m_2PL2 <- brm(
#   data = d2_rasch,
#   family = brmsfamily("bernoulli", "identity"),
#   bf(
#     correct ~ 0.5 + 0.5 * inv_logit(exp(logalpha) * eta),
#     eta ~ 1 + (1 |i| question_id) + (1 | sub_id),
#     logalpha ~ 1 + (1 |i| question_id),
#     nl = TRUE
#   ),
#   prior = prior_2PL,
#   control = list(adapt_delta = 0.95, max_treedepth = 12),
#   cores = 3,
#   chains = 3,
#   iter = 4000
# )%>%add_criterion(c("loo"))
# 
# saveRDS(m_2PL2, "./saves/m_2PL2.rds")

m_2PL2 <- readRDS("./saves/m_2PL2.rds")
```

## Indices

```{r}
items <- d%>%filter(qtype == "2AFC",answer_0_1 != "NA")%>% arrange(question_id)%>%distinct(question_id)%>%pull(question_id)

easiness_rasch <- bind_rows(
ranef(rasch_m)$question_id%>%as_tibble(rownames = "question_id"),
ranef(rasch_m2)$question_id%>%as_tibble(rownames = "question_id")
)%>% arrange(question_id)%>%
  pull(Estimate.eta_Intercept)

infit <- bind_rows(
  rasch_fit_mode%>% select(question_id, fit_index, mode)%>%pivot_wider(names_from = "fit_index", values_from = "mode"),
  rasch_fit_mode2%>% select(question_id, fit_index, mode)%>%pivot_wider(names_from = "fit_index", values_from = "mode")
)%>% arrange(question_id)%>% 
  pull(infit)

outfit <- bind_rows(
  rasch_fit_mode%>% select(question_id, fit_index, mode)%>%pivot_wider(names_from = "fit_index", values_from = "mode"),
  rasch_fit_mode2%>% select(question_id, fit_index, mode)%>%pivot_wider(names_from = "fit_index", values_from = "mode")
)%>% arrange(question_id)%>% 
  pull(outfit)

disc_2PL <-bind_rows(
coef(m_2PL)$question_id[, , "logalpha_Intercept"] %>% as_tibble(rownames = "question_id"),
coef(m_2PL2)$question_id[, , "logalpha_Intercept"] %>% as_tibble(rownames = "question_id"))%>% arrange(question_id)%>% 
  pull(Estimate)




```

## Annealing algorithm 

```{r}
score_fn <- function(subset) {
	easinesses <- sort(easiness_rasch[subset])
	nn_dists <- rep(0, sum(subset)-1)
	for(i in 1:sum(subset)-1) {
		nn_dists[i] <- easinesses[i+1] - easinesses[i]
	}
	spacing <- -1*sd(nn_dists)/3
	
	var_disc_sample <- disc_2PL[subset]
	var_disc_2PL <- -1*var(var_disc_sample)*10
	
	infit_sample <- infit[subset]
	infit_dist <- unlist(lapply(infit_sample, func))
  mean_infit <- -4*mean(infit_dist)
  
	outfit_sample <- outfit[subset]
	outfit_dist <- unlist(lapply(outfit_sample, func))
  mean_outfit <- -2*mean(outfit_dist)
  
	return(spacing + mean_infit + mean_outfit+ var_disc_2PL)
}


proposal_fn <- function(subset) {
	# Randomly sample a number of swaps.
	# Prefer a small number of swaps for "fine tuning", but allow
	# occasional large numbers of swaps, including a complete
	# exchange of the subset
	subset_size = sum(as.integer(subset))
	max_swaps = min(subset_size, length(subset) - subset_size)
	swaps <- rbinom(1, max_swaps-1, 1/(max_swaps-1)) + 1

	# Choose the items to swap
	active_items <- seq(1:length(subset))[subset == TRUE]
	inactive_items <- seq(1:length(subset))[subset == FALSE]
	actives_to_swap <- sample(active_items, swaps)
	inactives_to_swap <- sample(inactive_items, swaps)

	# Do the swapping
	for(i in 1:swaps) {
		subset[actives_to_swap[i]] <- FALSE
		subset[inactives_to_swap[i]] <- TRUE
	}
	return(subset)
}

simulated_annealing <- function(k, cooling_ratio=0.999, reset_thresh=1000, break_thresh=10000) {
  
  items <- items
  easiness_rasch <- easiness_rasch
  infit <- infit
  outfit <- outfit
  disc_2PL <- disc_2PL

  N <- length(easiness_rasch)

	current_subset <- sample(c(rep(TRUE, k), rep(FALSE, N-k)))
	best_subset <- current_subset
	best_score <- score_fn(best_subset)

	temp <- 100
	rejected <- 0
	no_new_bests <- 0
	for(i in 1:1e6) {
		# Score new subset, and toss a coin
		new_subset <- proposal_fn(current_subset)
		new_score <- score_fn(new_subset)
		accept_decrease <- rbernoulli(1, temp / 100)

		# Accept the new subset if it's an improvement, or if our
		# cooling coin came up heads.
		if(new_score > best_score | accept_decrease) {
			current_subset <- new_subset
			rejected <- 0
			if(new_score > best_score) {
				best_subset <- new_subset
				best_score <- new_score
				no_new_bests <- 0
			} else {
				no_new_bests <- no_new_bests + 1
			}
		# Quit if we've had too many rejections in a row.
		} else {
			rejected <- rejected + 1
			no_new_bests <- no_new_bests + 1
			if(rejected == break_thresh) {
				#print(best_score)
			  ret <- tibble(best_subset = list(best_subset),
	              best_score = best_score)
			  
				return(ret)
			}
		}
		# Start random resets to the current best subset if we haven't
		# found anything better in quite a while.
		if(no_new_bests > reset_thresh & rbernoulli(1, 1/100)) {
			current_subset <- best_subset
		}

		# Cool it!
		temp <- temp*cooling_ratio
	}
	#print(best_score)
	ret <- tibble(best_subset = list(best_subset),
	              best_score = best_score)
	
	return(ret)
}
```

## Automated item slection

Test run

```{r}
test_20 <- simulated_annealing(20)

test_sel_items <- items[unlist(test_20$best_subset) == TRUE]
```

Ask selection algorithm to select 20 items 100 times 

```{r}
item_sel <- tibble()

for (i in 1:100) {

   sim <- simulated_annealing(20)

   sel <- items[unlist(sim$best_subset) == TRUE]

   it <- d%>%
     distinct(question_id)%>%
     filter(question_id %in% sel)%>%
     select(question_id)%>%
     mutate(iter = i)

   item_sel <- bind_rows(item_sel, it)
}

saveRDS(item_sel, "./saves/item_sel.rds")

item_sel <- readRDS("./saves/item_sel.rds")

```

Plot how often items were selected. No item was selected every time but some items were selected most of the time (20 items were selected 61 times or more).

```{r}
item_sel%>%
  group_by(question_id)%>%
  summarise(n = n())%>%
  arrange(-n)%>%
  ggplot(aes(x = reorder(question_id, -n), y = n))+
  geom_bar(stat = "identity", col = "black", fill = "white")+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```
Select 20 most often selected items

```{r}
final_sel_items <- item_sel%>%
  group_by(question_id)%>%
  summarise(n = n())%>%
  arrange(-n)%>%
  head(20)%>%
  pull(question_id)
```
Which items were selected? Check wording. Most of them require some form of false belief reasoning. 

```{r}
d|>
  filter(question_id %in% final_sel_items)|>
  distinct(question_id, .keep_all = T)|>
  select(question_id, concept_super, question)
```
## ICCs for selected items

Visualize Rasch ICC for items 

```{r}
comb_icc_rasch <- bind_rows(
  posterior_samples(rasch_m)%>% 
  select(b_eta_Intercept, starts_with("r_question_id"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_question_id"), names_to = "item", values_to = "xi") %>%
  mutate(item = str_extract(string = item, pattern = "(?<=\\[).*(?=,Intercept\\])")),
  
  posterior_samples(rasch_m2)%>% 
  select(b_eta_Intercept, starts_with("r_question_id"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_question_id"), names_to = "item", values_to = "xi") %>%
  mutate(item = str_extract(string = item, pattern = "(?<=\\[).*(?=,Intercept\\])"))
  
  
)%>%
  filter(item %in% final_sel_items)%>%
  expand(nesting(iter, b_eta_Intercept, item, xi),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = 0.5 + 0.5*inv_logit_scaled((b_eta_Intercept + theta + xi))) %>%  
  group_by(theta, item) %>% 
  summarise(p = mean(p))%>%
  left_join(d%>%select(question_id,concept_super, dataset)%>%rename(item = question_id)%>%distinct(item, .keep_all = T))
```

```{r}
comb_icc_rasch %>% 
  #filter(item %in% sel_items_rasch)%>%
  ggplot(aes(x = theta, y = p,group = item, col = concept_super, lty = dataset)) +
  geom_line() +
  #facet_wrap(~group)+
  #guides(col = F)+
  geom_hline(yintercept = 0.5, lty = 3, alpha = .75)+
  scale_color_viridis_d(name = "Category") +
  labs(title = "ICCs for the 1PL",
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  ylim(0,1)+
  theme_minimal()
```
Visualize 2PL ICC for items 

```{r}

comb_icc_2PL <- bind_rows(
posterior_samples(m_2PL)%>% 
  select(b_eta_Intercept, b_logalpha_Intercept, starts_with("r_question_id"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_question_id")) %>%
  mutate(item      = str_extract(name, pattern = "(?<=\\[).*(?=,Intercept\\])"),
         parameter = ifelse(str_detect(name, "eta"), "xi", "logalpha"))%>%
  select(-name) %>% 
  pivot_wider(names_from = parameter, values_from = value),

posterior_samples(m_2PL2)%>% 
  select(b_eta_Intercept, b_logalpha_Intercept, starts_with("r_question_id"))%>%
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_question_id")) %>%
  mutate(item      = str_extract(name, pattern = "(?<=\\[).*(?=,Intercept\\])"),
         parameter = ifelse(str_detect(name, "eta"), "xi", "logalpha"))%>%
  select(-name) %>% 
  pivot_wider(names_from = parameter, values_from = value)

)%>%
  filter(item %in% final_sel_items)%>% 
  expand(nesting(iter, b_eta_Intercept, b_logalpha_Intercept, item, xi, logalpha),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  # note the difference in the equation
  mutate(p = 0.5 + 0.5*inv_logit_scaled(exp(b_logalpha_Intercept + logalpha) * (b_eta_Intercept + theta + xi))) %>% 
  group_by(theta, item) %>% 
  summarise(p = mean(p))%>%
  left_join(d%>%select(question_id,concept_super, dataset)%>%rename(item = question_id)%>%distinct(item, .keep_all = T))
```

```{r}
comb_icc_2PL %>% 
  #filter(item %in% sel_items_rasch)%>%
  ggplot(aes(x = theta, y = p,group = item, col = concept_super, lty = dataset)) +
  geom_line() +
  #facet_wrap(~group)+
  #guides(col = F)+
  geom_hline(yintercept = 0.5, lty = 3, alpha = .75)+
  scale_color_viridis_d(name = "Category") +
  labs(title = "ICCs for the 2PL",
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  ylim(0,1)+
  theme_minimal()
```

There is a cluster of medium difficult items that all require false belief reasoning, either directly or embedded in moral reasoning. 
